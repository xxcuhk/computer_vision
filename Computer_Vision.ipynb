{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGvkz_cMXKcg"
      },
      "source": [
        "Copyright @ CUHK Jockey Club AI for the Future Project\n",
        "## Computer Vision\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/xxcuhk/computer_vision/blob/main/Computer_Vision.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3yTLpJIiouf"
      },
      "source": [
        "# Step 1: Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kufdpPzXjXLp"
      },
      "source": [
        "1. Runtime, Factory reset runtime\n",
        "2. Runtime, Change runtime type, Hardware accelerator: GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCWAmdYTWzex"
      },
      "source": [
        "## Step 1.1: Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9BBNPeRZrFo"
      },
      "outputs": [],
      "source": [
        "# Import library\n",
        "\n",
        "import os # library for interation with operation system, for manipulating folders\n",
        "import tensorflow as tf # machine learning library\n",
        "import numpy as np # library for working with arrays\n",
        "import matplotlib.pyplot as plt # library for plotting figures, pyplot provides MATLAB-like plot\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import shutil # high-level file operations\n",
        "import pathlib # object-oriented filesystem paths\n",
        "\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fR-cssJ182Gf"
      },
      "outputs": [],
      "source": [
        "# Setting parameters\n",
        "\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "BATCH_SIZE = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "799iW3eiUWRS"
      },
      "source": [
        "## Step 1.2: Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_c2DA56iX4T"
      },
      "outputs": [],
      "source": [
        "# Download data\n",
        "# Print directory tree\n",
        "\n",
        "# tf.keras.utils.get_file: download a file from a URL if it not already in the cache\n",
        "# origin: original URL of the file\n",
        "# extract: true tries extracting the file as an Archive, like tar or zip\n",
        "zip_dir = tf.keras.utils.get_file(origin=\"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\", extract=True)\n",
        "\n",
        "# os.path.dirname(path): return the directory name of pathname path\n",
        "zip_dir_base = os.path.dirname(zip_dir)\n",
        "\n",
        "# os.walk(top, topdown=True): get the root, directory, file name in a directory tree by walking the tree\n",
        "# returns 3-tuple (dirpath, dirnames, filenames)\n",
        "for root, dirs, files in os.walk(zip_dir_base, topdown=True):\n",
        "  print(root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QckDjZ0_iZvm"
      },
      "outputs": [],
      "source": [
        "# Print number of files in each folder\n",
        "\n",
        "# os.path.join: join one or more path components intelligently\n",
        "base_dir = os.path.join(zip_dir_base, \"cats_and_dogs_filtered\") # base directory\n",
        "train_dir = os.path.join(base_dir, \"train\") # directory with training images\n",
        "validation_dir = os.path.join(base_dir, \"validation\") # directory with validation images\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, \"cats\")  # directory with training cat images\n",
        "train_dogs_dir = os.path.join(train_dir, \"dogs\")  # directory with training dog images\n",
        "validation_cats_dir = os.path.join(validation_dir, \"cats\")  # directory with validation cat images\n",
        "validation_dogs_dir = os.path.join(validation_dir, \"dogs\")  # directory with validation dog images\n",
        "\n",
        "# os.path.isdir: check if path is an existing directory\n",
        "# os.listdir: return a list containing the names of the entries in the directory given by path\n",
        "if os.path.isdir(train_cats_dir):\n",
        "  print(\"file number in folder:\", train_cats_dir, \"is: \", len(os.listdir(train_cats_dir)))\n",
        "\n",
        "if os.path.isdir(train_dogs_dir):\n",
        "  print(\"file number in folder:\", train_dogs_dir, \"is: \", len(os.listdir(train_dogs_dir)))\n",
        "\n",
        "if os.path.isdir(validation_cats_dir):\n",
        "  print(\"file number in folder:\", validation_cats_dir, \"is: \", len(os.listdir(validation_cats_dir)))\n",
        "\n",
        "if os.path.isdir(validation_dogs_dir):\n",
        "  print(\"file number in folder:\", validation_dogs_dir, \"is: \", len(os.listdir(validation_dogs_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wK2xOY76i704"
      },
      "outputs": [],
      "source": [
        "# Create new folders\n",
        "# Print number of files in the new folders\n",
        "\n",
        "# os.path.join: join one or more path components intelligently\n",
        "# os.path.isdir: check if path is an existing directory\n",
        "# os.mkdir: create a directory named path with numeric mode mode\n",
        "new_cats_dir = os.path.join(base_dir, \"cats\") # create new folder for all cat images\n",
        "if not os.path.isdir(new_cats_dir):\n",
        "  os.mkdir(new_cats_dir)\n",
        "\n",
        "new_dogs_dir = os.path.join(base_dir, \"dogs\") # create new folder for all dog images\n",
        "if not os.path.isdir(new_dogs_dir):\n",
        "  os.mkdir(new_dogs_dir)\n",
        "\n",
        "for root, dirs, files in os.walk(zip_dir_base, topdown=True):\n",
        "  print(root)\n",
        "\n",
        "# os.listdir: return a list containing the names of the entries in the directory given by path\n",
        "print(\"\\nfile number in folder:\", new_cats_dir, \"is: \", len(os.listdir(new_cats_dir)))\n",
        "print(\"file number in folder:\", new_dogs_dir, \"is: \", len(os.listdir(new_dogs_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJkusyBt8Y8n"
      },
      "outputs": [],
      "source": [
        "# Move all the files from old folders to new folders\n",
        "\n",
        "# os.path.isdir: check if path is an existing directory\n",
        "# os.listdir: return a list containing the names of the entries in the directory given by path\n",
        "# shutil.copy2: copy file to other file or directory\n",
        "if os.path.isdir(train_cats_dir):\n",
        "  files=os.listdir(train_cats_dir)\n",
        "  for fname in files:\n",
        "    shutil.copy2(os.path.join(train_cats_dir,fname), new_cats_dir)\n",
        "\n",
        "if os.path.isdir(train_dogs_dir):\n",
        "  files=os.listdir(train_dogs_dir)\n",
        "  for fname in files:\n",
        "    shutil.copy2(os.path.join(train_dogs_dir,fname), new_dogs_dir)\n",
        "\n",
        "if os.path.isdir(validation_cats_dir):\n",
        "  files=os.listdir(validation_cats_dir)\n",
        "  for fname in files:\n",
        "    shutil.copy2(os.path.join(validation_cats_dir,fname), new_cats_dir)\n",
        "\n",
        "if os.path.isdir(validation_dogs_dir):\n",
        "  files=os.listdir(validation_dogs_dir)\n",
        "  for fname in files:\n",
        "    shutil.copy2(os.path.join(validation_dogs_dir,fname), new_dogs_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsVwqB8Q7uQd"
      },
      "outputs": [],
      "source": [
        "# Delete the old directory\n",
        "\n",
        "# os.path.isdir: check if path is an existing directory\n",
        "# shutil.rmtree: delete an entire directory tree\n",
        "if os.path.isdir(train_dir):\n",
        "  shutil.rmtree(train_dir)\n",
        "\n",
        "if os.path.isdir(validation_dir):\n",
        "  shutil.rmtree(validation_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErlzyRuQUi0_"
      },
      "source": [
        "## Step 1.3: Explore Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UO0pZB48gZ_"
      },
      "outputs": [],
      "source": [
        "# Print directory tree\n",
        "# Print number of files in each folder\n",
        "\n",
        "# os.walk(top, topdown=True): get the root, directory, file name in a directory tree by walking the tree\n",
        "# returns 3-tuple (dirpath, dirnames, filenames)\n",
        "for root, dirs, files in os.walk(zip_dir_base, topdown=True):\n",
        "  print(root)\n",
        "\n",
        "# os.listdir: return a list containing the names of the entries in the directory given by path\n",
        "print(\"\\nfile number in folder:\", new_cats_dir, \"is: \", len(os.listdir(new_cats_dir)))\n",
        "print(\"file number in folder:\", new_dogs_dir, \"is: \", len(os.listdir(new_dogs_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvPIxWJMCBZi"
      },
      "outputs": [],
      "source": [
        "# Print some sample images\n",
        "\n",
        "# pathlib.Path: paths\n",
        "# Path.glob: glob the given relative pattern in the directory represented by this path, yielding all matching files (of any kind)\n",
        "cats = list(pathlib.Path(new_cats_dir).glob(\"*\"))\n",
        "dogs = list(pathlib.Path(new_dogs_dir).glob(\"*\"))\n",
        "\n",
        "# Print sample cat images\n",
        "# tf.keras.preprocessing.image.load_img: load an image into PIL format\n",
        "# random.randint(a, b): return a random integer N such that a <= N <= b\n",
        "for i in range(2):\n",
        "  img = tf.keras.preprocessing.image.load_img(cats[random.randint(0,len(cats)-1)]) # load a random cat image\n",
        "  fig = plt.gcf() # create a new figure\n",
        "  fig.set_size_inches(img.size[0]/100,img.size[1]/100) # set figure size\n",
        "  plt.axis(\"off\") # turn off axis lines and labels\n",
        "  plt.imshow(img) # display data as an image\n",
        "  plt.show() # display all open figures\n",
        "  img = np.array(img) # Image to numpy array\n",
        "  print(img.shape) # print image shape\n",
        "\n",
        "# Print sample dog images\n",
        "for i in range(2):\n",
        "  img = tf.keras.preprocessing.image.load_img(dogs[random.randint(0,len(dogs)-1)])\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(img.size[0]/100,img.size[1]/100)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(img)\n",
        "  plt.show()\n",
        "  img = np.array(img)\n",
        "  print(img.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVWNGY6_UtAv"
      },
      "source": [
        "# Step 2: Preprocess Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2.1: Resize the Images & Data Labelling"
      ],
      "metadata": {
        "id": "sWCeOiemKIX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define empty lists\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# resize to target size, label cat images as 0\n",
        "for i in cats:\n",
        "  image=tf.keras.preprocessing.image.load_img(i, color_mode=\"rgb\", target_size=(IMG_HEIGHT,IMG_WIDTH)) # load image\n",
        "  image=np.array(image) # Image to numpy array\n",
        "  data.append(image) # append image to list\n",
        "  labels.append(0) # append label (0 for cat) to list\n",
        "\n",
        "######## Please complete the code below ########\n",
        "# resize to target size, label dog images as 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data = np.array(data) # list to numpy array\n",
        "labels = np.array(labels) # list to numpy array"
      ],
      "metadata": {
        "id": "onKiH-MCKM1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Answer**"
      ],
      "metadata": {
        "id": "bzvw8h7wdbbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define empty lists\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# resize to target size, label cat images as 0\n",
        "for i in cats:\n",
        "  image=tf.keras.preprocessing.image.load_img(i, color_mode=\"rgb\", target_size=(IMG_HEIGHT,IMG_WIDTH)) # load image\n",
        "  image=np.array(image) # Image to numpy array\n",
        "  data.append(image) # append image to list\n",
        "  labels.append(0) # append label (0 for cat) to list\n",
        "\n",
        "# resize to target size, label dog images as 1\n",
        "for i in dogs:\n",
        "  image=tf.keras.preprocessing.image.load_img(i, color_mode=\"rgb\", target_size=(IMG_HEIGHT,IMG_WIDTH))\n",
        "  image=np.array(image)\n",
        "  data.append(image)\n",
        "  labels.append(1)\n",
        "\n",
        "data = np.array(data) # list to numpy array\n",
        "labels = np.array(labels) # list to numpy array"
      ],
      "metadata": {
        "id": "-v8VuJWXdgPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2.2: Dataset Split"
      ],
      "metadata": {
        "id": "xQQOwLOxLD9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_test_split: split arrays or matrices into random train and test subsets\n",
        "\n",
        "# first split 80% as training set, 20% as validation set + testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, shuffle=True, test_size=0.2, stratify=labels)\n",
        "\n",
        "######## Please complete the code below ########\n",
        "# then split 20% as 10% for validation set, 10% for testing set\n",
        "X_val, X_test, y_val, y_test = train_test_split(stratify=y_test)\n",
        "\n",
        "print(\"X_train: \",X_train.shape)\n",
        "print(\"X_val: \",X_val.shape)\n",
        "print(\"X_test: \",X_test.shape)\n",
        "print(\"y_train: \",y_train.shape)\n",
        "print(\"y_val: \",y_val.shape)\n",
        "print(\"y_test: \",y_test.shape)"
      ],
      "metadata": {
        "id": "gvIvkBqTdpb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Answer**"
      ],
      "metadata": {
        "id": "OiRKxn0HdnF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_test_split: split arrays or matrices into random train and test subsets\n",
        "\n",
        "# first split 80% as training set, 20% as validation set + testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, shuffle=True, test_size=0.2, stratify=labels)\n",
        "\n",
        "# then split 20% as 10% for validation set, 10% for testing set\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, shuffle=True, test_size=0.5, stratify=y_test)\n",
        "\n",
        "print(\"X_train: \",X_train.shape)\n",
        "print(\"X_val: \",X_val.shape)\n",
        "print(\"X_test: \",X_test.shape)\n",
        "print(\"y_train: \",y_train.shape)\n",
        "print(\"y_val: \",y_val.shape)\n",
        "print(\"y_test: \",y_test.shape)"
      ],
      "metadata": {
        "id": "jPiaFRQsMByP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2.3: Rescale the Pixel Values & Data Augmentation"
      ],
      "metadata": {
        "id": "9yWnuocjL_hD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ImageDataGenerator: generate batches of tensor image data with real-time data augmentation\n",
        "\n",
        "######## Please complete the code below ########\n",
        "# rescale and augment the training data\n",
        "train_image_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=,\n",
        "    width_shift_range=,\n",
        "    height_shift_range=,\n",
        "    shear_range=,\n",
        "    zoom_range=[0.2,1.8],\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# rescale and augment the validation data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# rescale and augment the testing data\n",
        "test_image_generator = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "9CzNkv_MNuxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Answer**"
      ],
      "metadata": {
        "id": "uZJ4x085d2A-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ImageDataGenerator: generate batches of tensor image data with real-time data augmentation\n",
        "\n",
        "# rescale and augment the training data\n",
        "train_image_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=45,\n",
        "    zoom_range=[0.2,1.8],\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# rescale and augment the validation data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# rescale and augment the testing data\n",
        "test_image_generator = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "7s_uu_N7d1dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2.4: Generate Batches"
      ],
      "metadata": {
        "id": "uLv-Q9crMa4G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVweDN9F9QGD"
      },
      "outputs": [],
      "source": [
        "# ImageDataGenerator.flow: takes data & label arrays, generates batches of augmented data\n",
        "train_generator = train_image_generator.flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
        "validation_generator = validation_image_generator.flow(X_val, y_val, batch_size=1)\n",
        "test_generator = test_image_generator.flow(X_test, y_test, batch_size=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_sEKpdHVMsE"
      },
      "source": [
        "# Step 3: Build Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######## Please complete the code below ########\n",
        "# input, image shape (batch size,IMG_HEIGHT,IMG_WIDTH,3)\n",
        "img_input = tf.keras.layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "\n",
        "# convolutional layer, 16 filters, filter size (3,3)\n",
        "# activation function, ReLU\n",
        "x = tf.keras.layers.Conv2D(16, 3, activation=\"relu\")(img_input)\n",
        "\n",
        "# pooling layer, max pooling, window size over which to take the maximum is (2,2)\n",
        "x = tf.keras.layers.MaxPooling2D(2)(x)\n",
        "\n",
        "\n",
        "# convolutional layer, 32 filters, filter size (3,3)\n",
        "# activation function, ReLU\n",
        "x =\n",
        "\n",
        "# pooling layer, max pooling, window size over which to take the maximum is (2,2)\n",
        "x =\n",
        "\n",
        "\n",
        "# convolutional layer, 64 filters, filter size (3,3)\n",
        "# activation function, ReLU\n",
        "x =\n",
        "\n",
        "# pooling layer, max pooling, window size over which to take the maximum is (2,2)\n",
        "x =\n",
        "\n",
        "\n",
        "# flatten layer\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "# fully-connected layer, 512 neurons\n",
        "# activation function, ReLU\n",
        "x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
        "# fully-connected layer, 1 neuron\n",
        "# activation function, sigmoid, class score (probability)\n",
        "output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = tf.keras.Model(img_input, output) # groups layers into an object\n",
        "model.summary() # print a string summary of the network\n",
        "\n",
        "\n",
        "# configures the model for training\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), # optimizer Adam, learning rate 0.001\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(), # loss function BinaryCrossentropy\n",
        "              metrics=\"accuracy\") # metrics accuracy"
      ],
      "metadata": {
        "id": "33ztJ80ZO9Q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Answer**"
      ],
      "metadata": {
        "id": "uB4PPPMNeElI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input, image shape (batch size,IMG_HEIGHT,IMG_WIDTH,3)\n",
        "img_input = tf.keras.layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "\n",
        "# convolutional layer, 16 filters, filter size (3,3)\n",
        "# activation function, ReLU\n",
        "x = tf.keras.layers.Conv2D(16, 3, activation=\"relu\")(img_input)\n",
        "\n",
        "# pooling layer, max pooling, window size over which to take the maximum is (2,2)\n",
        "x = tf.keras.layers.MaxPooling2D(2)(x)\n",
        "\n",
        "\n",
        "# convolutional layer, 32 filters, filter size (3,3)\n",
        "# activation function, ReLU\n",
        "x = tf.keras.layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
        "\n",
        "# pooling layer, max pooling, window size over which to take the maximum is (2,2)\n",
        "x = tf.keras.layers.MaxPooling2D(2)(x)\n",
        "\n",
        "\n",
        "# convolutional layer, 64 filters, filter size (3,3)\n",
        "# activation function, ReLU\n",
        "x = tf.keras.layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
        "\n",
        "# pooling layer, max pooling, window size over which to take the maximum is (2,2)\n",
        "x = tf.keras.layers.MaxPooling2D(2)(x)\n",
        "\n",
        "\n",
        "# flatten layer\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "# fully-connected layer, 512 neurons\n",
        "# activation function, ReLU\n",
        "x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
        "# fully-connected layer, 1 neuron\n",
        "# activation function, sigmoid, class score (probability)\n",
        "output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = tf.keras.Model(img_input, output) # groups layers into an object\n",
        "model.summary() # print a string summary of the network\n",
        "\n",
        "\n",
        "# configures the model for training\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), # optimizer Adam, learning rate 0.001\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(), # loss function BinaryCrossentropy\n",
        "              metrics=\"accuracy\") # metrics accuracy"
      ],
      "metadata": {
        "id": "pOX5wFayeG9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hmqaj_lVTn4"
      },
      "source": [
        "# Step 4: Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TY6XAr9k_hN5"
      },
      "outputs": [],
      "source": [
        "# Train model\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=int(np.ceil(X_train.shape[0] / float(BATCH_SIZE))), # training set size/batch size\n",
        "      epochs=50, # iterations on a dataset\n",
        "      validation_data=validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dkzr_6BvEDQS"
      },
      "outputs": [],
      "source": [
        "# Plot figures of loss and accuracy\n",
        "\n",
        "loss = history.history[\"loss\"] # loss for training set\n",
        "val_loss = history.history[\"val_loss\"] # loss for validation set\n",
        "\n",
        "acc = history.history[\"accuracy\"] # accuracy for training set\n",
        "val_acc = history.history[\"val_accuracy\"] # accuracy for valication set\n",
        "\n",
        "fig = plt.gcf() # create a new figure\n",
        "fig.set_size_inches(8, 2) # set figure size\n",
        "plt.subplot(1, 2, 1) # add subplot\n",
        "plt.plot(range(len(loss)), loss, label=\"Training Loss\") # plot loss for training set\n",
        "plt.plot(range(len(val_loss)), val_loss, label=\"Validation Loss\") # plot loss for validation set\n",
        "plt.legend(loc=\"upper right\") # location of the legend\n",
        "plt.ylim(0, 2.5) # set limits of y axis\n",
        "plt.title(\"Training and Validation Loss\") # set title\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(len(acc)), acc, label=\"Training Accuracy\")\n",
        "plt.plot(range(len(val_acc)), val_acc, label=\"Validation Accuracy\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.ylim(0, 1.0)\n",
        "plt.title(\"Training and Validation Accuracy\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LzPAQDQVYvw"
      },
      "source": [
        "# Step 5: Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_malZHDhLZv0"
      },
      "outputs": [],
      "source": [
        "# Evaluate model\n",
        "\n",
        "print(\"Evaluate on test data\")\n",
        "results = model.evaluate(test_generator)\n",
        "print(\"test loss, test acc:\", results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6n5ygtGS0YjU"
      },
      "outputs": [],
      "source": [
        "# Make predictions for some random samples\n",
        "\n",
        "class_label = {0:\"Cat\",1:\"Dog\"} # dictionary to map class to class label\n",
        "X_test_rescaled = X_test / 255.0 # rescale X_test data\n",
        "randomlist = random.sample(range(0,len(X_test)-1), 10) # some random samples\n",
        "y_pred = np.round(model.predict(X_test,batch_size=1)) # make predictions\n",
        "\n",
        "fig = plt.gcf() # create a new figure\n",
        "for i in range(len(randomlist)):\n",
        "  print(class_label[y_pred[randomlist[i]][0]]) # print class label\n",
        "  plt.axis(\"off\") # turn off axis lines and labels\n",
        "  plt.imshow(X_test[randomlist[i]]) # display data as an image\n",
        "  plt.show() # display all open figures"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}